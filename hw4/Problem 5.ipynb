{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20856b3",
   "metadata": {},
   "source": [
    "# Problem 5 : Non CE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07932326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy loss\n",
      "[Test set] Average loss: 0.1749, Accuracy: 1894/1991 (95.13%)\n",
      "\n",
      "Mean squared loss\n",
      "[Test set] Average loss: 0.1007, Accuracy: 1896/1991 (95.23%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "'''\n",
    "Step 1: Data\n",
    "'''\n",
    "# Use data with only 4 and 9 as labels: which is hardest to classify\n",
    "label_1, label_2 = 4, 9\n",
    "\n",
    "# MNIST training data\n",
    "train_set = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Use data with two labels\n",
    "idx = (train_set.targets == label_1) + (train_set.targets == label_2)\n",
    "train_set.data = train_set.data[idx]\n",
    "train_set.targets = train_set.targets[idx]\n",
    "train_set.targets[train_set.targets == label_1] = -1\n",
    "train_set.targets[train_set.targets == label_2] = 1\n",
    "\n",
    "# MNIST testing data\n",
    "test_set = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Use data with two labels\n",
    "idx = (test_set.targets == label_1) + (test_set.targets == label_2)\n",
    "test_set.data = test_set.data[idx]\n",
    "test_set.targets = test_set.targets[idx]\n",
    "test_set.targets[test_set.targets == label_1] = -1\n",
    "test_set.targets[test_set.targets == label_2] = 1\n",
    "    \n",
    "\n",
    "'''\n",
    "Step 2: (same step)\n",
    "'''\n",
    "class Linear(nn.Module) :\n",
    "\n",
    "    def __init__(self, input_dim=28*28) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return self.linear(x.float().view(-1, 28*28))\n",
    "\n",
    "'''\n",
    "Step 3: Create the model, specify loss function and optimizer. (LOOK HERE)\n",
    "'''\n",
    "model_CE = Linear()\n",
    "model_MSE = Linear()\n",
    "\n",
    "def CE_loss(output, target):\n",
    "    return torch.mean(-torch.nn.functional.logsigmoid(target.reshape(-1)*output.reshape(-1)))\n",
    "\n",
    "def MSE_loss(output, target):\n",
    "    output = output.reshape(-1)\n",
    "    target = target.reshape(-1)\n",
    "    B = len(output)\n",
    "    total = 0\n",
    "    for i in range(B):\n",
    "        y = target[i] \n",
    "        z = output[i]\n",
    "        total += 0.5*(1-y)*((1-torch.sigmoid(-z))**2 + torch.sigmoid(z)**2)\n",
    "        total += 0.5*(1+y)*(torch.sigmoid(-z)**2 + (1-torch.sigmoid(z))**2)\n",
    "    return total/B\n",
    "\n",
    "\n",
    "optimizer_CE = torch.optim.SGD(model_CE.parameters(), lr=255*1e-4)   \n",
    "optimizer_MSE = torch.optim.SGD(model_MSE.parameters(), lr=255*1e-4)   \n",
    "\n",
    "\n",
    "'''\n",
    "Step 4: Train model with SGD (LOOK HERE)\n",
    "'''\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(3) :\n",
    "    for images, labels in train_loader :\n",
    "        optimizer_CE.zero_grad()\n",
    "        optimizer_MSE.zero_grad()\n",
    "\n",
    "        train_loss_CE = CE_loss(model_CE(images), labels.float())\n",
    "        train_loss_CE.backward()\n",
    "        \n",
    "        train_loss_MSE = MSE_loss(model_MSE(images), labels.float())\n",
    "        train_loss_MSE.backward()\n",
    "\n",
    "        optimizer_CE.step()\n",
    "        optimizer_MSE.step()\n",
    "\n",
    "'''\n",
    "Step 5: (same step)\n",
    "'''\n",
    "test_loss_CE, correct_CE = 0, 0\n",
    "test_loss_MSE, correct_MSE = 0, 0\n",
    "\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "\n",
    "    output_CE = model_CE(image)\n",
    "    output_MSE = model_MSE(image)\n",
    "    test_loss_CE += CE_loss(output_CE, label.float()).item()\n",
    "    test_loss_MSE += MSE_loss(output_MSE, label.float()).item()\n",
    "\n",
    "\n",
    "    # Make a prediction\n",
    "    if output_CE.item() * label.item() >= 0 : \n",
    "        correct_CE += 1\n",
    "    if output_MSE.item() * label.item() >= 0 : \n",
    "        correct_MSE += 1\n",
    "\n",
    "# Print out the results\n",
    "print(\"Cross entropy loss\")\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss_CE /len(test_loader), correct_CE, len(test_loader),\n",
    "        100. * correct_CE / len(test_loader)))\n",
    "print(\"Mean squared loss\")\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss_MSE /len(test_loader), correct_MSE, len(test_loader),\n",
    "        100. * correct_MSE / len(test_loader)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eeb750",
   "metadata": {},
   "source": [
    "> 큰 차이가 없는 것으로 보여진다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
